{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7e76f90-b1a1-49c7-8335-29a648f770c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "import geopandas as gpd\n",
    "import shapely\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import dask_geopandas\n",
    "from tqdm import tqdm\n",
    "sys.path.append('c://projects//osm-flex/src') \n",
    "\n",
    "from rasterstats import point_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8edd12cc-1136-446b-94cc-16eb82dd2aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'c://data//CEED'\n",
    "input_data = os.path.join(data_path,'input_data')\n",
    "bucco_path = os.path.join(data_path,'coastal_bucco_exact')\n",
    "osm_path = os.path.join(data_path,'coastal_osm_exact')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "014ac0dd-e397-4dc2-bfeb-86d51639764a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def raster_to_vector(xr_raster):\n",
    "    \"\"\"\n",
    "    Convert a raster to a vector representation.\n",
    "\n",
    "    Args:\n",
    "        xr_raster (xarray.DataArray): Input raster data as xarray.DataArray.\n",
    "\n",
    "    Returns:\n",
    "        gpd.GeoDataFrame: Vector representation of the input raster.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert xarray raster to pandas DataFrame\n",
    "    df = xr_raster.to_dataframe()\n",
    "\n",
    "    # Filter DataFrame to select rows where band_data > 0\n",
    "    df_1 = df.loc[df.band_data > 0].reset_index()\n",
    "\n",
    "    # Create a Shapely Point geometry column from x and y values\n",
    "    df_1['geometry'] = shapely.points(df_1.x.values, df_1.y.values)\n",
    "\n",
    "    # Remove unnecessary columns from the DataFrame\n",
    "    df_1 = df_1.drop(['x', 'y', 'band', 'spatial_ref'], axis=1)\n",
    "\n",
    "    # Calculate the resolution of the raster\n",
    "    resolution = xr_raster.x[1].values - xr_raster.x[0].values\n",
    "\n",
    "    # Buffer the Point geometries by half of the resolution with square caps\n",
    "    df_1.geometry = shapely.buffer(df_1.geometry, distance=resolution/2, cap_style='square').values\n",
    "\n",
    "    # Convert the DataFrame to a GeoDataFrame\n",
    "    return gpd.GeoDataFrame(df_1)      \n",
    "\n",
    "def zonal_stats(vector, raster_in):\n",
    "    \"\"\"\n",
    "    Calculate zonal statistics of a raster dataset based on a vector dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    - vector_in (str): Path to the vector dataset file (in Parquet format).\n",
    "    - raster_in (str): Path to the raster dataset file (in NetCDF format).\n",
    "    \n",
    "    Returns:\n",
    "    - pandas.Series: A series containing the zonal statistics values corresponding to each centroid point in the vector dataset.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Open the raster dataset using the xarray library\n",
    "    raster = xr.open_dataset(raster_in, engine=\"rasterio\")\n",
    "    \n",
    "    # Progress bar setup for obtaining values\n",
    "    tqdm.pandas(desc='obtain values')\n",
    "    \n",
    "    # Clip the raster dataset to the bounding box of the vector dataset\n",
    "    raster_clip = raster.rio.clip_box(vector.total_bounds[0], vector.total_bounds[1], vector.total_bounds[2], vector.total_bounds[3])\n",
    "    \n",
    "    # Convert the clipped raster dataset to a vector representation\n",
    "    raster_vector = raster_to_vector(raster_clip)\n",
    "    \n",
    "    # Create a dictionary mapping each index to its corresponding band data value\n",
    "    band_data_dict = dict(zip(list(raster_vector.index), raster_vector['band_data'].values))\n",
    "    \n",
    "    # Construct an STRtree from the vector geometry values\n",
    "    tree = shapely.STRtree(raster_vector.geometry.values)\n",
    "    \n",
    "    # Apply a function to calculate zonal statistics for each centroid point in the vector dataset\n",
    "    return vector.centroid.progress_apply(lambda x: band_data_dict[tree.query(x, predicate='intersects')[0]])\n",
    "\n",
    "\n",
    "def vector_point_query(x, coastal_CLC_tree, band_data_dict):\n",
    "    \"\"\"\n",
    "    Perform a point query on a vector dataset based on specific conditions.\n",
    "\n",
    "    Parameters:\n",
    "    - x (GeoDataFrame): A GeoDataFrame representing a single feature.\n",
    "    - coastal_CLC_tree (shapely.STRtree): STRtree object constructed from the coastal CLC vector geometry values.\n",
    "    - band_data_dict (dict): A dictionary mapping indices to their corresponding band data values.\n",
    "\n",
    "    Returns:\n",
    "    - int: The band data value corresponding to the point query, or -9999 if the conditions are not met.\n",
    "    \"\"\"\n",
    "\n",
    "    if x.land_use == 5:\n",
    "        try:\n",
    "            # Perform an intersection query using the centroid of the feature\n",
    "            match = coastal_CLC_tree.query(x.centroid, predicate='intersects')\n",
    "            return band_data_dict[match[0]]\n",
    "        except:\n",
    "            # Return -9999 if no intersection is found\n",
    "            return -9999\n",
    "    else:\n",
    "        # Return -9999 if the land use condition is not met\n",
    "        return -9999\n",
    "    \n",
    "def final_land_use(x):\n",
    "    \"\"\"\n",
    "    Determine the final land use based on the coastal land use and land use values of a feature.\n",
    "\n",
    "    Parameters:\n",
    "    - x (pandas.Series): A pandas Series representing a single feature.\n",
    "\n",
    "    Returns:\n",
    "    - int: The final land use value, which is either the coastal land use or the land use value of the feature.\n",
    "    \"\"\"\n",
    "\n",
    "    if x.coastal_land_use == -9999:\n",
    "        return x.land_use\n",
    "    else:\n",
    "        return x.coastal_land_use  \n",
    "    \n",
    "def iso2_to_iso3(iso2):\n",
    "    \n",
    "    dict_ =  {\n",
    "            \"NL\" : \"NLD\",\n",
    "            \"FR\" : \"FRA\",\n",
    "            \"DE\" : \"NLD\",\n",
    "            \"SW\" : \"SWE\",\n",
    "            \"ES\" : \"ESP\",\n",
    "            \"PT\" : \"PRT\",\n",
    "            \"IT\" : \"ITA\",\n",
    "            \"HR\" : \"HRV\",\n",
    "            \"GR\" : \"GRC\",\n",
    "            \"MT\" : \"MLT\",\n",
    "            \"DK\" : \"DNK\",\n",
    "            \"BE\" : \"BEL\",\n",
    "            \"PL\" : \"POL\",\n",
    "            \"CY\" : \"CYP\",\n",
    "            \"FI\" : \"FIN\",\n",
    "            \"IE\" : \"IRL\",\n",
    "            \"EE\" : \"EST\",\n",
    "            \"LV\" : \"LVA\",\n",
    "            \"RO\" : \"ROU\",\n",
    "            \"BG\" : \"BGR\",\n",
    "            \"LT\" : \"LTU\"    \n",
    "            }\n",
    "    \n",
    "    return dict_[iso2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db84459-32d7-43c7-8c1f-8c8d262ea473",
   "metadata": {},
   "source": [
    "### Load nuts2 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "718e1798-6062-4ee0-b2b2-88a7836dfac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.42 s\n",
      "Wall time: 1.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nuts_europe = gpd.read_file(os.path.join(input_data,'NUTS_RG_03M_2021_3035.shp'))\n",
    "nuts2_europe = nuts_europe.loc[nuts_europe.LEVL_CODE == 2].reset_index(drop=True)\n",
    "nuts0_europe = nuts_europe.loc[nuts_europe.LEVL_CODE == 0].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b044c692-e410-4016-8c06-122db2934215",
   "metadata": {},
   "source": [
    "### LOAD CLC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bdd88e9-7330-476d-9948-17fdb79a1e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLC_path = os.path.join(input_data,'u2018_clc2018_v2020_20u1_raster100m','DATA','U2018_CLC2018_V2020_20u1.tif')\n",
    "coastal_CLC_path = os.path.join(input_data,'CZ_2018_DU004_3035_V010.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac4f147-0e22-4fb8-bd8d-595e9fabcd04",
   "metadata": {},
   "source": [
    "### Get coastal countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7b356f2-357f-4b61-a8ea-6905a1b2c866",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_codes = [x.split('.')[0][:3] for x in os.listdir(bucco_path) if x.endswith('.parquet')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "620f1895-7576-4df2-8980-770b65fd73dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_buildings(nuts2,nuts2_europe,bucco_path,CLC_path,coastal_CLC_path):\n",
    "\n",
    "    # get country iso2\n",
    "    country_iso2 = nuts2[:2]\n",
    "\n",
    "    #continue if not in a coastal country\n",
    "    try: \n",
    "        iso2_to_iso3(country_iso2)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "    # read nuts2 geometry\n",
    "    nuts2_geom = nuts2_europe.loc[nuts2_europe.NUTS_ID==nuts2].geometry.values[0]\n",
    "\n",
    "    # load buildings for the country\n",
    "    gdf_bucco = gpd.read_parquet(os.path.join(bucco_path,'{}_bucco.parquet'.format(iso2_to_iso3(country_iso2))))\n",
    "\n",
    "    # bounding box clip\n",
    "    bbox_buildings = gdf_bucco.iloc[gdf_bucco.centroid.clip(nuts2_geom.bounds).index].reset_index(drop=True)\n",
    "\n",
    "    if len(bbox_buildings) == 0:\n",
    "        return None\n",
    "    \n",
    "    # prepare geometry to improve speed of intersect\n",
    "    shapely.prepare(bbox_buildings.geometry.values)\n",
    "\n",
    "    # exact intersect of nuts2 with buildings\n",
    "    nuts2_buildings = bbox_buildings.loc[shapely.intersects(bbox_buildings.geometry.values,nuts2_geom)].reset_index(drop=True)   \n",
    "\n",
    "    if len(nuts2_buildings) == 0:\n",
    "        return None    \n",
    "    \n",
    "    # get land use information from CLC 2018\n",
    "    nuts2_buildings['land_use'] = zonal_stats(nuts2_buildings,CLC_path)\n",
    "\n",
    "    # read coastal corine land cover layer\n",
    "    coastal_CLC = gpd.read_parquet(coastal_CLC_path)\n",
    "    coastal_CLC_tree = shapely.STRtree(coastal_CLC.geometry.values)\n",
    "    band_data_dict = dict(zip(list(coastal_CLC.index), coastal_CLC['CODE_4_18'].values))\n",
    "\n",
    "    # get centroids to speed up intersect\n",
    "    nuts2_buildings['centroid'] = nuts2_buildings.centroid\n",
    "\n",
    "    # get port values\n",
    "    tqdm.pandas(desc='obtain port values')\n",
    "    nuts2_buildings['coastal_land_use'] = nuts2_buildings.progress_apply(lambda x: vector_point_query(x,coastal_CLC_tree,band_data_dict),axis=1)\n",
    "    \n",
    "    # get unique use type per building\n",
    "    tqdm.pandas(desc='get unique use type')\n",
    "    nuts2_buildings['use_type'] = nuts2_buildings.progress_apply(lambda x: final_land_use(x),axis=1)\n",
    "\n",
    "    nuts2_buildings = nuts2_buildings.drop(['centroid','land_use','coastal_land_use'],axis=1)\n",
    "    \n",
    "    return nuts2_buildings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ab189fb-e2b0-47bd-9ada-be8d3e6e31fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_cis(nuts2,nuts2_europe,osm_path):\n",
    "\n",
    "    # get country iso2\n",
    "    country_iso2 = nuts2[:2]\n",
    "\n",
    "    #continue if not in a coastal country\n",
    "    try: \n",
    "        iso2_to_iso3(country_iso2)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "    # read nuts2 geometry\n",
    "    nuts2_geom = nuts2_europe.loc[nuts2_europe.NUTS_ID==nuts2].geometry.values[0]\n",
    "\n",
    "    # load osm data for the country\n",
    "    country_cis = gpd.read_parquet(os.path.join(osm_path,'{}_cis.parquet'.format(iso2_to_iso3(country_iso2))))                          \n",
    "\n",
    "    # list of critical infrastructure types\n",
    "    cis = ['healthcare','education','gas','oil','telecom','water','wastewater','power','rail','road','air']\n",
    "    \n",
    "    cis_nuts = {}\n",
    "    for i_cis in cis:\n",
    "        sub_cis = country_cis.loc[i_cis] \n",
    "        sub_cis = sub_cis.to_crs(3035)    \n",
    "        \n",
    "        # bounding box clip\n",
    "        bbox_sub_cis = sub_cis.iloc[sub_cis.centroid.clip(nuts2_geom.bounds).index].reset_index(drop=True)\n",
    "\n",
    "        # prepare geometry to improve speed of intersect\n",
    "        shapely.prepare(bbox_sub_cis.geometry.values)\n",
    "\n",
    "        # exact intersect of nuts2 with buildings\n",
    "        nuts2_cis = bbox_sub_cis.loc[shapely.intersects(bbox_sub_cis.geometry.values,nuts2_geom)].reset_index(drop=True)   \n",
    "        \n",
    "        # drop duplicate geometries\n",
    "        nuts2_cis = nuts2_cis.iloc[nuts2_cis.geometry.to_wkt().drop_duplicates().index].reset_index(drop=True)\n",
    "        \n",
    "        cis_nuts[i_cis] = nuts2_cis\n",
    "    \n",
    "    return gpd.GeoDataFrame(pd.concat(cis_nuts))\n",
    "\n",
    "def nuts2_exposure(nuts2):\n",
    "    \n",
    "    data_path = 'c://data//CEED'\n",
    "    input_data = os.path.join(data_path,'input_data')\n",
    "    bucco_path = os.path.join(data_path,'coastal_bucco_exact')\n",
    "    osm_path = os.path.join(data_path,'coastal_osm_exact')\n",
    "    \n",
    "    nuts_europe = gpd.read_file(os.path.join(input_data,'NUTS_RG_03M_2021_3035.shp'))\n",
    "    nuts2_europe = nuts_europe.loc[nuts_europe.LEVL_CODE == 2].reset_index(drop=True)\n",
    "    \n",
    "    nuts2_buildings = prepare_buildings(nuts2,nuts2_europe,bucco_path,CLC_path,coastal_CLC_path)\n",
    "\n",
    "    nuts2_cis = prepare_cis(nuts2,nuts2_europe,osm_path)\n",
    "\n",
    "    all_asset_types = ['buildings','healthcare','education','gas','oil','telecom','water','wastewater','power','rail','road','air']\n",
    "    \n",
    "    combine_all = {}\n",
    "    for asset_type in all_asset_types:\n",
    "        try:\n",
    "            if asset_type == 'buildings':\n",
    "                combine_all[asset_type] = nuts2_buildings\n",
    "\n",
    "            else:\n",
    "                combine_all[asset_type] = nuts2_cis.loc[asset_type]\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "    # save file\n",
    "    out_path = os.path.join(data_path,'nuts2_CEED','{}_CEED.parquet'.format(nuts2)\n",
    "    \n",
    "    gpd.GeoDataFrame(pd.concat(combine_all)).to_parquet(out_path)        \n",
    "    \n",
    "    return gpd.GeoDataFrame(pd.concat(combine_all))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639876f8-fce2-49f9-b58b-70a9a23a3340",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "nuts_pilots = ['FRI3','ES21','ITC3','ES52']\n",
    "for nuts2 in nuts_pilots:\n",
    "    nuts2_combined = nuts2_exposure(nuts2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f420b3-5dd9-480b-b883-b0cdfb66be64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
