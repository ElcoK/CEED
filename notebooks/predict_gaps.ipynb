{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7fa466c-dd10-451b-a8e0-65fbb5505fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "import geopandas as gpd\n",
    "import shapely\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, roc_auc_score, roc_curve, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "sys.path.append('c://projects//osm-flex/src') \n",
    "\n",
    "from rasterstats import point_query\n",
    "\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6bb0b5f-6955-4294-b2ce-e4029bc6eb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def landuse_simplified(value):\n",
    "\n",
    "    land_use_dict = {\n",
    "    1 : 1,\n",
    "    2 : 2,\n",
    "    3 : 3,\n",
    "    4 : 4,\n",
    "    5 : 5,\n",
    "    6 : 6,\n",
    "    7 : 7,\n",
    "    8 : 8,\n",
    "    9 : 9,\n",
    "    10 : 10,\n",
    "    11 : 11,\n",
    "    12 : 12,\n",
    "    13 : 12,\n",
    "    14 : 12,\n",
    "    15 : 12,\n",
    "    16 : 13,\n",
    "    17 : 13,\n",
    "    18 : 14,\n",
    "    19 : 15,\n",
    "    20 : 15,\n",
    "    21 : 15,\n",
    "    22 : 16,\n",
    "    23 : 16,\n",
    "    24 : 16,\n",
    "    25 : 16,\n",
    "    26 : 16,\n",
    "    27 : 16,\n",
    "    28 : 16,\n",
    "    29 : 16,\n",
    "    30 : 17,\n",
    "    31 : 17,\n",
    "    32 : 17,\n",
    "    33 : 17,\n",
    "    34 : 17,\n",
    "    35 : 18,\n",
    "    36 : 18,\n",
    "    37 : 18,\n",
    "    38 : 18,\n",
    "    39 : 18,\n",
    "    40 : 19,\n",
    "    41 : 19,\n",
    "    42 : 19,\n",
    "    43 : 19,\n",
    "    44 : 19,\n",
    "    48 : 19,    }    \n",
    "    \n",
    "    return land_use_dict[value]\n",
    "\n",
    "\n",
    "def raster_to_vector(xr_raster):\n",
    "    \"\"\"\n",
    "    Convert a raster to a vector representation.\n",
    "\n",
    "    Args:\n",
    "        xr_raster (xarray.DataArray): Input raster data as xarray.DataArray.\n",
    "\n",
    "    Returns:\n",
    "        gpd.GeoDataFrame: Vector representation of the input raster.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert xarray raster to pandas DataFrame\n",
    "    df = xr_raster.to_dataframe()\n",
    "\n",
    "    # Filter DataFrame to select rows where band_data is 1\n",
    "    df_1 = df.loc[df.band_data > 0].reset_index()\n",
    "\n",
    "    # Create a Shapely Point geometry column from x and y values\n",
    "    df_1['geometry'] = shapely.points(df_1.x.values, df_1.y.values)\n",
    "\n",
    "    # Remove unnecessary columns from the DataFrame\n",
    "    df_1 = df_1.drop(['x', 'y', 'band', 'spatial_ref'], axis=1)\n",
    "\n",
    "    # Calculate the resolution of the raster\n",
    "    resolution = xr_raster.x[1].values - xr_raster.x[0].values\n",
    "\n",
    "    # Buffer the Point geometries by half of the resolution with square caps\n",
    "    df_1.geometry = shapely.buffer(df_1.geometry, distance=resolution/2, cap_style='square').values\n",
    "\n",
    "    # Convert the DataFrame to a GeoDataFrame\n",
    "    return gpd.GeoDataFrame(df_1)      \n",
    "\n",
    "def zonal_stats(vector, raster_in):\n",
    "    \"\"\"\n",
    "    Calculate zonal statistics of a raster dataset based on a vector dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    - vector_in (str): Path to the vector dataset file (in Parquet format).\n",
    "    - raster_in (str): Path to the raster dataset file (in NetCDF format).\n",
    "    \n",
    "    Returns:\n",
    "    - pandas.Series: A series containing the zonal statistics values corresponding to each centroid point in the vector dataset.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Open the raster dataset using the xarray library\n",
    "    raster = xr.open_dataset(raster_in, engine=\"rasterio\")\n",
    "    \n",
    "    # Progress bar setup for obtaining values\n",
    "    tqdm.pandas(desc='obtain land-use values')\n",
    "    \n",
    "    # Clip the raster dataset to the bounding box of the vector dataset\n",
    "    raster_clip = raster.rio.clip_box(vector.total_bounds[0], vector.total_bounds[1], vector.total_bounds[2], vector.total_bounds[3])\n",
    "    \n",
    "    # Convert the clipped raster dataset to a vector representation\n",
    "    raster_vector = raster_to_vector(raster_clip)\n",
    "    \n",
    "    # Create a dictionary mapping each index to its corresponding band data value\n",
    "    band_data_dict = dict(zip(list(raster_vector.index), raster_vector['band_data'].values))\n",
    "    \n",
    "    # Construct an STRtree from the vector geometry values\n",
    "    tree = shapely.STRtree(raster_vector.geometry.values)\n",
    "    \n",
    "    # Apply a function to calculate zonal statistics for each centroid point in the vector dataset\n",
    "    return vector.centroid.progress_apply(lambda x: band_data_dict[tree.query(x, predicate='intersects')[0]])\n",
    "\n",
    "def develop_predictor(data, y_col='maxspeed', x_cols=['land_use', 'highway', 'lanes', 'surface'], inline=True):\n",
    "    \"\"\"\n",
    "    Trains a random forest classifier model to predict a target variable based on the given input features.\n",
    "    \n",
    "    Args:\n",
    "        data (pandas.DataFrame): The input data containing both the features and the target variable.\n",
    "        y_col (str, optional): The name of the target variable column in the data. Default is 'maxspeed'.\n",
    "        x_cols (list, optional): A list of feature column names in the data. Default is ['land_use', 'highway', 'lanes', 'surface'].\n",
    "        inline (bool, optional): Determines whether to print the model accuracy inline or return the model pipeline. \n",
    "                                If True, the accuracy is printed inline. If False, the model pipeline is returned. Default is True.\n",
    "    \n",
    "    Returns:\n",
    "        sklearn.pipeline.Pipeline or None: If inline is True, the function prints the model accuracy.\n",
    "                                           If inline is False, the function returns the trained model pipeline.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Separate the target variable and input features\n",
    "    y = data[y_col]\n",
    "    X = data[x_cols]\n",
    "        \n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.66)\n",
    "    \n",
    "    # Identify the categorical features for one-hot encoding\n",
    "    features_to_encode = X_train.columns[X_train.dtypes == object].tolist()\n",
    "       \n",
    "    # Create a column transformer to one-hot encode the categorical features and pass through the remaining features\n",
    "    col_trans = make_column_transformer(\n",
    "        (OneHotEncoder(), features_to_encode),\n",
    "        remainder=\"passthrough\"\n",
    "    )\n",
    "    \n",
    "    # Create a random forest classifier with specified parameters\n",
    "    rf_classifier = RandomForestClassifier(\n",
    "        criterion='gini',\n",
    "        min_samples_leaf=25,\n",
    "        n_estimators=50,\n",
    "        bootstrap=True,\n",
    "        oob_score=True,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    # Create a pipeline with the column transformer and random forest classifier\n",
    "    pipe = make_pipeline(col_trans, rf_classifier)\n",
    "    \n",
    "    # Train the model pipeline\n",
    "    pipe.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    \n",
    "    # Calculate the accuracy of the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Print the accuracy if inline is False\n",
    "    if not inline:\n",
    "        print(f\"The accuracy of the {y_col} model is {round(accuracy * 100, 3)} %\")\n",
    "    \n",
    "    # Return the model pipeline if inline is False\n",
    "    return pipe\n",
    "\n",
    "def fill_attributes(x,infra_specific_tag,pipe_dict,attributes):\n",
    "    \"\"\"\n",
    "    Fills missing attributes (e.g., maxspeed, lanes, and surface) in a data point using trained prediction models.\n",
    "    \n",
    "    Args:\n",
    "        x (pandas.Series): A single road data point containing 'landuse', 'highway', 'sinuosity', 'maxspeed', 'lanes', and 'surface' attributes.\n",
    "    \n",
    "    Returns:\n",
    "        pandas.Series: The updated road data point with filled missing attributes.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a DataFrame with the necessary features for prediction\n",
    "    X_pred = pd.DataFrame(x[['landuse', infra_specific_tag, 'sinuosity']]).T\n",
    "    \n",
    "    for attribute in attributes:\n",
    "        if x[attribute] is None:\n",
    "            x[attribute] = pipe_dict[attribute].predict(X_pred)[0]\n",
    "    \n",
    "    return x\n",
    "\n",
    "def sinuosity(geom):\n",
    "    if geom.geom_type == 'MultiPolygon':\n",
    "        return 1\n",
    "    elif geom.geom_type == 'LineString':      \n",
    "        return shapely.length(geom)/shapely.distance(shapely.get_point(geom,0),shapely.get_point(geom,-1))\n",
    "    \n",
    "def update_country_attributes(country_code, infra_type='road',\n",
    "                                            infra_specific_tag = ['highway'], \n",
    "                                            attributes=['surface','lanes','maxspeed'],\n",
    "                                            **kwargs):\n",
    "    \"\"\"\n",
    "    Updates road attributes (maxspeed, lanes, and surface) for a specific country based on various data sources and models.\n",
    "    \n",
    "    Args:\n",
    "        country_code (str): The country code for the country to update the road attributes.\n",
    "    \n",
    "    Returns:\n",
    "        geopandas.GeoDataFrame: A GeoDataFrame containing updated road attributes for the coastal areas of the country.\n",
    "    \"\"\"\n",
    "    \n",
    "      \n",
    "    # Set file paths for data sources and models   \n",
    "    data_path = 'c://data//CEED'\n",
    "    input_data = os.path.join(data_path,'input_data')\n",
    "    osm_path = os.path.join(data_path,'..','CIS_EU')\n",
    "    \n",
    "    bucco_file = os.path.join(input_data, '..', 'coastal_bucco_exact', '{}_bucco.parquet').format(country_code)\n",
    "    CLC_path = os.path.join(input_data, 'u2018_clc2018_v2020_20u1_raster100m', 'DATA', 'U2018_CLC2018_V2020_20u1.tif')\n",
    "    slope_path = os.path.join(input_data, 'eudem_slop_3035_europe.tif')\n",
    "    coastal_CLC_path = os.path.join(input_data, 'CZ_2018_DU004_3035_V010.parquet')\n",
    "    \n",
    "    # Read OSM data for the country\n",
    "    country_osm = gpd.read_parquet(os.path.join(osm_path, '{}_cis.parquet'.format(country_code)))   \n",
    "    \n",
    "    # Extract relevant road attributes and convert to the desired coordinate reference system\n",
    "    if kwargs is None:\n",
    "        infrastructure = gpd.GeoDataFrame(country_osm.loc[infra_type][['geometry']+infra_specific_tag+attributes])\n",
    "    \n",
    "    elif kwargs['geom_type'] == 'LineString':\n",
    "        infrastructure = gpd.GeoDataFrame(country_osm.loc[infra_type][['geometry']+infra_specific_tag+attributes])\n",
    "        infrastructure = infrastructure.loc[infrastructure.geometry.geom_type == 'LineString']\n",
    "        \n",
    "    infrastructure = infrastructure.to_crs(3035)\n",
    "    \n",
    "    # remove links from roads\n",
    "    if infra_type == 'road':\n",
    "        infrastructure[infra_specific_tag[0]] = infrastructure[infra_specific_tag[0]].str.rsplit(pat=\"_\",expand=True, n=0)[0]\n",
    "\n",
    "    # Perform zonal statistics to extract land use information for the roads\n",
    "    land_use = zonal_stats(infrastructure, CLC_path)\n",
    "    infrastructure['landuse'] = land_use\n",
    "    infrastructure['landuse'] = infrastructure['landuse'].apply(lambda x: landuse_simplified(x))\n",
    "    \n",
    "    # Calculate the sinuosity of each road and cap extreme values\n",
    "    tqdm.pandas(desc='obtain sinuosity')\n",
    "    infrastructure['sinuosity'] = infrastructure.geometry.progress_apply(lambda x: sinuosity(x))\n",
    "    infrastructure.sinuosity.loc[infrastructure.sinuosity > infrastructure.sinuosity.quantile(.98)] = infrastructure.sinuosity.quantile(.98)\n",
    "\n",
    "    # Drop rows with missing values\n",
    "    full_data = infrastructure.dropna()\n",
    "    \n",
    "    # Update infrequent surface values to the most common type\n",
    "    for attribute in attributes:\n",
    "        full_data.loc[full_data[attribute].map(full_data[attribute].value_counts(normalize=True).lt(0.005)), attribute] = full_data[attribute].value_counts().index[0]\n",
    "    \n",
    "    # Update infrequent landuse values with the minimum unique value\n",
    "    full_data.loc[full_data['landuse'].map(full_data['landuse'].value_counts(normalize=True).lt(0.005)), 'landuse'] = full_data['landuse'].value_counts().index[0]\n",
    "\n",
    "    # Convert landuse column to object type\n",
    "    full_data.landuse = full_data.landuse.astype('object')\n",
    "    \n",
    "    # Develop predictor models for lanes, maxspeed, and surface\n",
    "    pipe_dict = {}\n",
    "    for attribute in attributes:\n",
    "        pipe_dict[attribute] = develop_predictor(full_data, y_col=attribute, x_cols=['landuse', infra_specific_tag[0], 'sinuosity'], inline=False)\n",
    " \n",
    "    # Set paths for input and output coastal OSM data\n",
    "    coastal_path_in = os.path.join(data_path, 'coastal_osm_exact')\n",
    "    coastal_path_out = os.path.join(data_path, 'coastal_osm_filled')\n",
    "\n",
    "    # Read coastal OSM data for the country\n",
    "    coastal_osm = gpd.read_parquet(os.path.join(coastal_path_in, '{}_cis.parquet'.format(country_code)))\n",
    "    \n",
    "    if kwargs is None:\n",
    "        coastal_infra = gpd.GeoDataFrame(coastal_osm.loc[infra_type][['geometry']+infra_specific_tag+attributes])\n",
    "    elif kwargs['geom_type'] == 'LineString':\n",
    "        coastal_infra = gpd.GeoDataFrame(coastal_osm.loc[infra_type][['geometry']+infra_specific_tag+attributes])       \n",
    "        coastal_infra = coastal_infra.loc[infrastructure.geometry.geom_type == 'LineString']\n",
    "    \n",
    "    coastal_infra = coastal_infra.to_crs(3035)\n",
    "    \n",
    "    # remove 'links from highway'\n",
    "    if infra_type == 'road':\n",
    "        coastal_infra[infra_specific_tag[0]] = coastal_infra[infra_specific_tag[0]].str.rsplit(pat=\"_\",expand=True, n=0)[0]\n",
    "    \n",
    "    # Perform zonal statistics to extract land use information for the coastal roads\n",
    "    coastal_infra['landuse'] = zonal_stats(coastal_infra, CLC_path)\n",
    "    coastal_infra['landuse'] = coastal_infra['landuse'].apply(lambda x: landuse_simplified(x))\n",
    "    coastal_infra.landuse = coastal_infra.landuse.astype('object')\n",
    "    \n",
    "    # Calculate the sinuosity of each coastal road and cap extreme values\n",
    "    coastal_infra['sinuosity'] = coastal_infra.geometry.apply(lambda x: sinuosity(x))\n",
    "    coastal_infra.sinuosity.loc[coastal_infra.sinuosity > coastal_infra.sinuosity.quantile(.98)] = coastal_infra.sinuosity.quantile(.98)\n",
    "    \n",
    "    # Update infrequent highway values as the most common\n",
    "    coastal_infra.loc[coastal_infra[infra_specific_tag[0]].map(coastal_infra[infra_specific_tag[0]].value_counts(normalize=True).lt(0.005)), \n",
    "                      infra_specific_tag[0]] = coastal_infra[infra_specific_tag[0]].value_counts().index[0]\n",
    "\n",
    "    # Update infrequent landuse values with the most common value\n",
    "    coastal_infra.loc[coastal_infra['landuse'].map(coastal_infra['landuse'].value_counts(normalize=True).lt(0.1)), \n",
    "                      'landuse'] = coastal_infra.landuse.value_counts().index[0]\n",
    "    \n",
    "    coastal_infra.landuse = coastal_infra.landuse.astype('object')\n",
    "\n",
    "    # Fill missing road attributes for coastal roads using the fill_road_attributes function\n",
    "    tqdm.pandas(desc='fill missing values')\n",
    "    coastal_infra = coastal_infra.progress_apply(lambda x: fill_attributes(x,infra_specific_tag[0],pipe_dict,attributes), axis=1)\n",
    "    \n",
    "    # Update road attributes in the coastal OSM data with the filled values\n",
    "    for attribute in attributes:\n",
    "        if kwargs is None:\n",
    "            coastal_osm.loc[infra_type, attribute] = coastal_infra[attribute].values\n",
    "        elif kwargs['geom_type'] == 'LineString':\n",
    "            coastal_osm.loc[infra_type].loc[country_osm.loc[infra_type].geometry.geom_type == 'LineString'][attribute] = coastal_infra[attribute].values\n",
    "\n",
    "    return coastal_osm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8689a1-9298-40ea-8a1f-103854077d36",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "obtain land-use values: 100%|███████████████████████████████████████████████| 619527/619527 [00:08<00:00, 75132.59it/s]\n",
      "obtain sinuosity: 100%|█████████████████████████████████████████████████████| 619527/619527 [00:33<00:00, 18675.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the surface model is 91.612 %\n",
      "The accuracy of the lanes model is 61.634 %\n",
      "The accuracy of the maxspeed model is 67.088 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "obtain land-use values: 100%|███████████████████████████████████████████████| 177055/177055 [00:02<00:00, 74487.36it/s]\n",
      "fill missing values:  30%|███████████████▎                                    | 52235/177055 [25:38<1:13:49, 28.18it/s]"
     ]
    }
   ],
   "source": [
    "country_code = 'PRT'\n",
    "\n",
    "test = update_country_attributes(country_code, infra_type='road',\n",
    "                                            infra_specific_tag = ['highway'], \n",
    "                                            attributes=['surface','lanes','maxspeed'],geom_type='LineString')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d69dc2e-0718-494b-b54b-6181e16ee00e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "obtain land-use values: 100%|████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 5534.71it/s]\n",
      "obtain sinuosity: 100%|██████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 5504.34it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m country_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMLT\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 3\u001b[0m test_rail \u001b[38;5;241m=\u001b[39m \u001b[43mupdate_country_attributes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcountry_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfra_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrail\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43minfra_specific_tag\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrailway\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mattributes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgauge\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43melectrified\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mgeom_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLineString\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[5], line 262\u001b[0m, in \u001b[0;36mupdate_country_attributes\u001b[1;34m(country_code, infra_type, infra_specific_tag, attributes, **kwargs)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;66;03m# Update infrequent surface values to the most common type\u001b[39;00m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m attribute \u001b[38;5;129;01min\u001b[39;00m attributes:\n\u001b[1;32m--> 262\u001b[0m     full_data\u001b[38;5;241m.\u001b[39mloc[full_data[attribute]\u001b[38;5;241m.\u001b[39mmap(full_data[attribute]\u001b[38;5;241m.\u001b[39mvalue_counts(normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mlt(\u001b[38;5;241m0.005\u001b[39m)), attribute] \u001b[38;5;241m=\u001b[39m \u001b[43mfull_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mattribute\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue_counts\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# Update infrequent landuse values with the minimum unique value\u001b[39;00m\n\u001b[0;32m    265\u001b[0m full_data\u001b[38;5;241m.\u001b[39mloc[full_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlanduse\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap(full_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlanduse\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts(normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mlt(\u001b[38;5;241m0.005\u001b[39m)), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlanduse\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m full_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlanduse\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\u001b[38;5;241m.\u001b[39mindex[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\.conda\\envs\\py_s\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5320\u001b[0m, in \u001b[0;36mIndex.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   5317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(key) \u001b[38;5;129;01mor\u001b[39;00m is_float(key):\n\u001b[0;32m   5318\u001b[0m     \u001b[38;5;66;03m# GH#44051 exclude bool, which would return a 2d ndarray\u001b[39;00m\n\u001b[0;32m   5319\u001b[0m     key \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mcast_scalar_indexer(key, warn_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m-> 5320\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgetitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5322\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mslice\u001b[39m):\n\u001b[0;32m   5323\u001b[0m     \u001b[38;5;66;03m# This case is separated from the conditional above to avoid\u001b[39;00m\n\u001b[0;32m   5324\u001b[0m     \u001b[38;5;66;03m# pessimization com.is_bool_indexer and ndim checks.\u001b[39;00m\n\u001b[0;32m   5325\u001b[0m     result \u001b[38;5;241m=\u001b[39m getitem(key)\n",
      "\u001b[1;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "country_code = 'BEL'\n",
    "\n",
    "test_rail = update_country_attributes(country_code, infra_type='rail',\n",
    "                                            infra_specific_tag = ['railway'], \n",
    "                                            attributes=['gauge','electrified'],geom_type='LineString')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9edbfe-e920-416d-b035-f2f5fef8b910",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
